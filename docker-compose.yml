# docker-compose.yml
# Production setup for OCR Frontend project

version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ocr_frontend_db
    restart: unless-stopped
    environment:
      POSTGRES_DB: n8n
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: P@ssw0rd
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    networks:
      - ocr_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d n8n"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend API Service (Express.js from src/server.js)
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: ocr_frontend_backend
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3001
      API_PREFIX: /api
      
      # Database
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: admin
      DB_POSTGRESDB_PASSWORD: P@ssw0rd
      
      # File uploads
      UPLOAD_DIR: uploads
      MAX_FILE_SIZE: 52428800
      ALLOWED_FILE_TYPES: pdf,jpg,jpeg,png
      MAX_FILES_PER_UPLOAD: 1000
      
      # OCR Services
      TYPHOON_API_KEY: sk-k3P9pmjvgqhv9Xb8YzsKiVhczsZP1irSKAswUP7jWrdvVlxm
      TYPHOON_OCR_URL: https://api.opentyphoon.ai/v1/ocr
      FASTAPI_OCR_URL: http://localhost:8001
      
      # AI Configuration
      OLLAMA_BASE_URL: http://localhost:7869
      
      CORS_ORIGIN: http://localhost:3000
    ports:
      - "3001:3001"
    volumes:
      - uploads_data:/app/uploads
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ocr_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Frontend React App (Vite build)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      args:
        # AI Configuration for frontend
        REACT_APP_AI_PROVIDER: mock
        REACT_LOCAL_AI_URL: http://localhost:7869
        REACT_APP_LOCAL_MODEL: qwen3:0.6b
        REACT_APP_ENABLE_AI_CHAT: true
        REACT_APP_ENABLE_FILE_ANALYSIS: true
        REACT_APP_DEBUG_AI: false
    container_name: ocr_frontend_ui
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - ocr_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Local AI (Ollama) service
  ollama:
    image: ollama/ollama:latest
    container_name: ocr_ollama
    restart: unless-stopped
    ports:
      - "7869:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ocr_network
    environment:
      - OLLAMA_HOST=0.0.0.0
    profiles:
      - ai  # Use with: docker-compose --profile ai up

  # nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: ocr_nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - uploads_data:/var/www/uploads:ro
    depends_on:
      - frontend
      - backend
    networks:
      - ocr_network

volumes:
  postgres_data:
    driver: local
  uploads_data:
    driver: local
  ollama_data:
    driver: local

networks:
  ocr_network:
    driver: bridge